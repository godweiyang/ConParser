[Data]
data_dir = data
train_file = %(data_dir)s/02-21.10way.clean
dev_file = %(data_dir)s/22.auto.clean
test_file = %(data_dir)s/23.auto.clean
train_bert_file = %(data_dir)s/bert/train_bert.txt
dev_bert_file = %(data_dir)s/bert/dev_bert.txt
test_bert_file = %(data_dir)s/bert/test_bert.txt

[Save]
save_dir = ckpt/ChartParser
config_file = %(save_dir)s/config.cfg
save_model_path = %(save_dir)s/
load_dir = ckpt/ChartParser
load_model_path = %(load_dir)s/
evalb_dir = run/EVALB/

[Network]
num_layers = 8
d_model = 1024
num_heads = 8
d_kv = 64
d_ff = 2048
d_label_hidden = 250
d_char_emb = 32
attention_dropout = 0.2
embedding_dropout = 0.0
relu_dropout = 0.1
residual_dropout = 0.2
tag_emb_dropout=0.2
word_emb_dropout = 0.4
morpho_emb_dropout = 0.2
timing_dropout = 0.0
char_lstm_input_dropout = 0.2
elmo_dropout = 0.5

[Optimizer]
clip_grad_norm = 0
learning_rate = 0.0008
learning_rate_warmup_steps = 160
step_decay = True
step_decay_factor = 0.5
step_decay_patience = 5

[Run]
random_seed = 666
numpy_seed = 666
torch_seed = 666
max_len_train = 0
max_len_dev = 0
sentence_max_len = 300
partitioned = True
num_layers_position_only = 0
use_tags = False
use_words = False
use_chars_lstm = False
use_chars_concat = False
use_elmo = False
batch_size = 10
epochs = 50
checks_per_epoch = 4
subbatch_max_tokens = 2000
